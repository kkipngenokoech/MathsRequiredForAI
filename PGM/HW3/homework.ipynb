{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METROPOLIS HASTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "premier_league_2013_2014.dat not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m norm, gamma, poisson\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpremier_league_2013_2014.dat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m y_g1 \u001b[38;5;241m=\u001b[39m data[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Goals scored by home team\u001b[39;00m\n\u001b[1;32m      8\u001b[0m y_g2 \u001b[38;5;241m=\u001b[39m data[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Goals scored by away team\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/MathsRequiredForAI/EnvMaths/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:1381\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1379\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1381\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/projects/MathsRequiredForAI/EnvMaths/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:997\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m    995\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fname)\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 997\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    999\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/MathsRequiredForAI/EnvMaths/lib/python3.12/site-packages/numpy/lib/_datasource.py:192\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/MathsRequiredForAI/EnvMaths/lib/python3.12/site-packages/numpy/lib/_datasource.py:532\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    530\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: premier_league_2013_2014.dat not found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, gamma, poisson\n",
    "\n",
    "# Load the data\n",
    "data = np.loadtxt('premier_league_2013_2014.dat')\n",
    "y_g1 = data[:, 0]  # Goals scored by home team\n",
    "y_g2 = data[:, 1]  # Goals scored by away team\n",
    "h_g = data[:, 2].astype(int)  # Home team index\n",
    "a_g = data[:, 3].astype(int)  # Away team index\n",
    "\n",
    "# Parameters\n",
    "n_teams = 20\n",
    "n_games = len(data)\n",
    "tau_0 = 0.0001  # Prior precision for home\n",
    "tau_1 = 0.0001  # Prior precision for mean parameters\n",
    "alpha = 0.1     # Gamma shape parameter\n",
    "beta = 0.1      # Gamma rate parameter\n",
    "\n",
    "# Set up parameter vector\n",
    "# Order: home, att_1,...,att_19, def_1,...,def_19, mu_att, mu_def, tau_att, tau_def\n",
    "n_params = 1 + (n_teams-1) + (n_teams-1) + 4  # home + att + def + hyperparams\n",
    "att_start_idx = 1\n",
    "def_start_idx = att_start_idx + (n_teams-1)\n",
    "hyper_start_idx = def_start_idx + (n_teams-1)\n",
    "\n",
    "def log_likelihood(params):\n",
    "    \"\"\"Compute log likelihood of the data given parameters.\"\"\"\n",
    "    home = params[0]\n",
    "    att = np.zeros(n_teams)\n",
    "    att[1:] = params[att_start_idx:def_start_idx]  # att_0 = 0\n",
    "    \n",
    "    def_ = np.zeros(n_teams)\n",
    "    def_[1:] = params[def_start_idx:hyper_start_idx]  # def_0 = 0\n",
    "    \n",
    "    mu_att = params[hyper_start_idx]\n",
    "    mu_def = params[hyper_start_idx + 1]\n",
    "    tau_att = params[hyper_start_idx + 2]\n",
    "    tau_def = params[hyper_start_idx + 3]\n",
    "    \n",
    "    # Ensure tau parameters are positive\n",
    "    if tau_att <= 0 or tau_def <= 0:\n",
    "        return -np.inf\n",
    "    \n",
    "    # Calculate theta values\n",
    "    log_theta_g1 = home + att[h_g] - def_[a_g]\n",
    "    log_theta_g2 = att[a_g] - def_[h_g]\n",
    "    \n",
    "    theta_g1 = np.exp(log_theta_g1)\n",
    "    theta_g2 = np.exp(log_theta_g2)\n",
    "    \n",
    "    # Log likelihood for observed goals\n",
    "    ll_goals = np.sum(poisson.logpmf(y_g1, theta_g1) + poisson.logpmf(y_g2, theta_g2))\n",
    "    \n",
    "    # Log prior for home\n",
    "    ll_home = norm.logpdf(home, 0, np.sqrt(1/tau_0))\n",
    "    \n",
    "    # Log prior for attack parameters\n",
    "    ll_att = np.sum(norm.logpdf(att[1:], mu_att, np.sqrt(1/tau_att)))\n",
    "    \n",
    "    # Log prior for defense parameters\n",
    "    ll_def = np.sum(norm.logpdf(def_[1:], mu_def, np.sqrt(1/tau_def)))\n",
    "    \n",
    "    # Log hyperpriors\n",
    "    ll_mu_att = norm.logpdf(mu_att, 0, np.sqrt(1/tau_1))\n",
    "    ll_mu_def = norm.logpdf(mu_def, 0, np.sqrt(1/tau_1))\n",
    "    ll_tau_att = gamma.logpdf(tau_att, alpha, scale=1/beta)\n",
    "    ll_tau_def = gamma.logpdf(tau_def, alpha, scale=1/beta)\n",
    "    \n",
    "    return ll_goals + ll_home + ll_att + ll_def + ll_mu_att + ll_mu_def + ll_tau_att + ll_tau_def\n",
    "\n",
    "def metropolis_hastings(n_burn, n_samples, thin, sigma):\n",
    "    \"\"\"\n",
    "    Run Metropolis-Hastings algorithm.\n",
    "    \n",
    "    Args:\n",
    "        n_burn: Number of burn-in samples\n",
    "        n_samples: Number of samples to collect after burn-in\n",
    "        thin: Thinning factor (keep every thin-th sample)\n",
    "        sigma: Standard deviation for isotropic Gaussian proposal\n",
    "    \n",
    "    Returns:\n",
    "        burn_samples: Samples from burn-in phase\n",
    "        samples: Collected samples after burn-in\n",
    "    \"\"\"\n",
    "    # Initialize parameters at 0\n",
    "    current_params = np.zeros(n_params)\n",
    "    current_params[hyper_start_idx + 2] = 1.0  # tau_att init\n",
    "    current_params[hyper_start_idx + 3] = 1.0  # tau_def init\n",
    "    \n",
    "    current_ll = log_likelihood(current_params)\n",
    "    \n",
    "    # Store burn-in samples\n",
    "    burn_samples = np.zeros((n_burn, n_params))\n",
    "    \n",
    "    # Burn-in phase\n",
    "    for i in range(n_burn):\n",
    "        # Propose new parameters\n",
    "        proposal = current_params + np.random.normal(0, sigma, n_params)\n",
    "        \n",
    "        # Handle tau parameters to ensure they're positive\n",
    "        if proposal[hyper_start_idx + 2] <= 0:\n",
    "            proposal[hyper_start_idx + 2] = np.abs(proposal[hyper_start_idx + 2])\n",
    "        if proposal[hyper_start_idx + 3] <= 0:\n",
    "            proposal[hyper_start_idx + 3] = np.abs(proposal[hyper_start_idx + 3])\n",
    "        \n",
    "        # Compute log likelihood of proposal\n",
    "        proposal_ll = log_likelihood(proposal)\n",
    "        \n",
    "        # Accept/reject step\n",
    "        log_accept_ratio = proposal_ll - current_ll\n",
    "        \n",
    "        if np.log(np.random.random()) < log_accept_ratio:\n",
    "            current_params = proposal\n",
    "            current_ll = proposal_ll\n",
    "        \n",
    "        burn_samples[i] = current_params\n",
    "        \n",
    "        if (i+1) % 1000 == 0:\n",
    "            print(f\"Burn-in iteration {i+1}/{n_burn}\")\n",
    "    \n",
    "    # Collect samples with thinning\n",
    "    total_iter = n_samples * thin\n",
    "    samples = np.zeros((n_samples, n_params))\n",
    "    \n",
    "    for i in range(total_iter):\n",
    "        # Propose new parameters\n",
    "        proposal = current_params + np.random.normal(0, sigma, n_params)\n",
    "        \n",
    "        # Handle tau parameters to ensure they're positive\n",
    "        if proposal[hyper_start_idx + 2] <= 0:\n",
    "            proposal[hyper_start_idx + 2] = np.abs(proposal[hyper_start_idx + 2])\n",
    "        if proposal[hyper_start_idx + 3] <= 0:\n",
    "            proposal[hyper_start_idx + 3] = np.abs(proposal[hyper_start_idx + 3])\n",
    "        \n",
    "        # Compute log likelihood of proposal\n",
    "        proposal_ll = log_likelihood(proposal)\n",
    "        \n",
    "        # Accept/reject step\n",
    "        log_accept_ratio = proposal_ll - current_ll\n",
    "        \n",
    "        if np.log(np.random.random()) < log_accept_ratio:\n",
    "            current_params = proposal\n",
    "            current_ll = proposal_ll\n",
    "        \n",
    "        # Store sample if it's a thinning iteration\n",
    "        if (i+1) % thin == 0:\n",
    "            samples[(i+1)//thin - 1] = current_params\n",
    "        \n",
    "        if (i+1) % 1000 == 0:\n",
    "            print(f\"Sampling iteration {i+1}/{total_iter}\")\n",
    "    \n",
    "    return burn_samples, samples\n",
    "\n",
    "# Run MCMC\n",
    "n_burn = 5000\n",
    "n_samples = 5000\n",
    "thin = 5\n",
    "sigma = 0.05\n",
    "\n",
    "burn_samples, samples = metropolis_hastings(n_burn, n_samples, thin, sigma)\n",
    "\n",
    "# Plot trace plot for home parameter (first parameter)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Burning phase\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(n_burn), burn_samples[:, 0])\n",
    "plt.title('Trace plot for home (burn-in phase)')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('home')\n",
    "\n",
    "# Post burn-in samples\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(n_samples), samples[:, 0])\n",
    "plt.title('Trace plot for home (post burn-in samples)')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('home')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('home_trace.png')\n",
    "plt.show()\n",
    "\n",
    "# Print mean estimate of home\n",
    "print(f\"Estimated posterior mean of home: {np.mean(samples[:, 0]):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvMaths",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
