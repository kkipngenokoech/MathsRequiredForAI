{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The California Housing Dataset is a widely used dataset that contains information about various at-\n",
    "tributes of houses in California, including median house values, median income, housing age, and more.\n",
    "We will focus on estimating the original value of a key variable that has been corrupted by artificial\n",
    "noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-Step Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset:\n",
    "• Use the sklearn.datasets module to load the California Housing Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 20640\n",
      "\n",
      ":Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      ":Attribute Information:\n",
      "    - MedInc        median income in block group\n",
      "    - HouseAge      median house age in block group\n",
      "    - AveRooms      average number of rooms per household\n",
      "    - AveBedrms     average number of bedrooms per household\n",
      "    - Population    block group population\n",
      "    - AveOccup      average number of household members\n",
      "    - Latitude      block group latitude\n",
      "    - Longitude     block group longitude\n",
      "\n",
      ":Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. rubric:: References\n",
      "\n",
      "- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "  Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install scikit-learn package\n",
    "# %pip install scikit-learn\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load the California Housing Dataset\n",
    "california_housing = fetch_california_housing()\n",
    "print(california_housing.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce Noise:\n",
    "- Select a variable, such as the ”Average Number of Rooms” (AveRooms), and add Gaussian noise to simulate corruption.\n",
    "- Use a Gaussian noise distribution with mean µ = 0 and standard deviation σ = 0.5.\n",
    "- The observed variable Y can be represented as:\n",
    "            Y = X + N, where N ∼ N (0, 0.52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original AveRooms: [6.98412698 6.23813708 8.28813559 5.8173516  6.28185328 4.76165803\n",
      " 4.93190661 4.79752705 4.29411765 4.97058824]\n",
      "Noisy AveRooms: [6.52847361 6.70832328 8.55627713 6.4772958  6.23292944 4.48225858\n",
      " 5.23959147 4.36891299 3.99219524 5.41638942]\n",
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "5  4.0368      52.0  4.761658   1.103627       413.0  2.139896     37.85   \n",
      "6  3.6591      52.0  4.931907   0.951362      1094.0  2.128405     37.84   \n",
      "7  3.1200      52.0  4.797527   1.061824      1157.0  1.788253     37.84   \n",
      "8  2.0804      42.0  4.294118   1.117647      1206.0  2.026891     37.84   \n",
      "9  3.6912      52.0  4.970588   0.990196      1551.0  2.172269     37.84   \n",
      "\n",
      "   Longitude  AveRooms_Noisy  \n",
      "0    -122.23        6.528474  \n",
      "1    -122.22        6.708323  \n",
      "2    -122.24        8.556277  \n",
      "3    -122.25        6.477296  \n",
      "4    -122.25        6.232929  \n",
      "5    -122.25        4.482259  \n",
      "6    -122.25        5.239591  \n",
      "7    -122.25        4.368913  \n",
      "8    -122.26        3.992195  \n",
      "9    -122.25        5.416389  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Extract the \"Average Number of Rooms\" (AveRooms) variable\n",
    "ave_rooms = california_housing.data[:, california_housing.feature_names.index('AveRooms')]\n",
    "\n",
    "# Generate Gaussian noise with mean 0 and standard deviation 0.5\n",
    "noise = np.random.normal(0, 0.5, ave_rooms.shape)\n",
    "\n",
    "# Add the noise to the \"Average Number of Rooms\" variable\n",
    "ave_rooms_noisy = ave_rooms + noise\n",
    "\n",
    "# Print the first 10 values to verify\n",
    "print(\"Original AveRooms:\", ave_rooms[:10])\n",
    "print(\"Noisy AveRooms:\", ave_rooms_noisy[:10])\n",
    "# Add the noisy \"Average Number of Rooms\" as a new column to the dataset\n",
    "\n",
    "# Convert the dataset to a DataFrame\n",
    "df = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
    "\n",
    "# Add the noisy AveRooms to the DataFrame\n",
    "df['AveRooms_Noisy'] = ave_rooms_noisy\n",
    "\n",
    "# Print the first 10 rows to verify\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split:\n",
    "- Split the data into training and testing sets using an 80-20 split ratio. This means 80% of the data will be used for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample the Data:\n",
    "- After splitting the dataset, randomly select 200 points from the test set to reduce clutter in visualizations and focus on key trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "3752    2.8208      33.0  4.051020   1.158163       739.0  1.885204     34.17   \n",
      "16705   4.3611      11.0  5.419753   0.962963       655.0  2.695473     35.06   \n",
      "2915    4.3482       9.0  5.792453   1.103774       409.0  1.929245     35.36   \n",
      "9728    4.5787      20.0  6.117371   0.995305      1361.0  3.194836     36.85   \n",
      "3352    2.5000      19.0  6.153153   1.252252       302.0  2.720721     40.28   \n",
      "18318   5.6413      35.0  5.361702   0.928191      1023.0  2.720745     37.44   \n",
      "10337   6.0531      25.0  5.833333   1.002110      1666.0  3.514768     33.80   \n",
      "6483    3.6944      29.0  4.048744   0.985229      2449.0  3.617430     34.08   \n",
      "17798  12.3292      29.0  7.916667   1.055556       244.0  3.388889     37.38   \n",
      "12532   2.2031      36.0  4.170068   1.129252       425.0  2.891156     38.57   \n",
      "\n",
      "       Longitude  AveRooms_Noisy  \n",
      "3752     -118.38        4.348473  \n",
      "16705    -120.52        5.370916  \n",
      "2915     -119.06        6.039335  \n",
      "9728     -121.65        6.988279  \n",
      "3352     -120.96        6.388365  \n",
      "18318    -122.11        5.613456  \n",
      "10337    -117.81        6.108857  \n",
      "6483     -118.02        3.527995  \n",
      "17798    -121.81        7.126049  \n",
      "12532    -121.51        4.851161  \n"
     ]
    }
   ],
   "source": [
    "# Randomly select 200 points from the test set\n",
    "test_sampled = test_set.sample(n=200, random_state=42)\n",
    "\n",
    "# Print the first 10 rows to verify\n",
    "print(test_sampled.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Best Linear Estimator:\n",
    "- Implement the best linear estimator (e.g., linear regression) to estimate the original values of the corrupted variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted AveRooms: [5.00340181 4.62768127 5.8525844  5.14937177 6.7224136  5.44674462\n",
      " 6.04677165 4.72074961 9.70019531 5.15432582]\n",
      "Actual AveRooms: [4.05102041 5.41975309 5.79245283 6.11737089 6.15315315 5.36170213\n",
      " 5.83333333 4.04874446 7.91666667 4.17006803]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data for linear regression\n",
    "X_train = train_set.drop(columns=['AveRooms', 'AveRooms_Noisy'])\n",
    "y_train = train_set['AveRooms']\n",
    "X_test = test_sampled.drop(columns=['AveRooms', 'AveRooms_Noisy'])\n",
    "y_test = test_sampled['AveRooms']\n",
    "\n",
    "# Initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the original values of the corrupted variable on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the first 10 predicted values to verify\n",
    "print(\"Predicted AveRooms:\", y_pred[:10])\n",
    "print(\"Actual AveRooms:\", y_test.values[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Estimator:\n",
    "- Calculate the bias and Mean Squared Error (MSE) of the estimator. Analyze how close the estimated values are to the original values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvMaths",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
